{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPdraft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgM3Ic7N4MxTlHlUp94n6h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASTigran/BCS_SpeechEmotionRecognition/blob/main/MLPdraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENpMs1oXOUlN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfBMrNxAJr_i"
      },
      "source": [
        "#defining function to extract features from database\n",
        "\n",
        "def f_ext(x,features,sr=10000):\n",
        "  ft = np.array([])\n",
        "  for f in features:\n",
        "   \n",
        "    if f=='chroma':\n",
        "      chroma = librosa.ft.chroma_stft(x,sr=sr)\n",
        "      ft = np.concatenate((ft,np.mean(chroma.T,axis=0)),axis=0)\n",
        "    if f=='mfcc':\n",
        "      mfccs = librosa.ft.mfcc(x,sr=sr )\n",
        "      ft = np.concatenate((ft,np.mean(mfccs.T,axis=0)),axis=0)  \n",
        "    if f=='mel':\n",
        "      mel_spec = librosa.ft.melspectrogram(x)\n",
        "      ft = np.concatenate((ft,np.mean(mel_spec.T,axis=0)),axis=0)\n",
        "    \n",
        "    \n",
        "  return ft\n",
        "\n",
        " # dataset loading\n",
        "\n",
        "def load_ds(type='emotion',features =['mel','mfcc','chroma']):                     \n",
        "  dir = 'enter path here'\n",
        "  X = []\n",
        "  Y = []\n",
        "  for j in os.listdir(dir):\n",
        "    x,sr = librosa.load(dir+'/'+j)\n",
        "    ft = f_ext(x,features)\n",
        "    X.append(ft)\n",
        "    if type =='emotion':                                \n",
        "      y = int(j.split('-')[2][1])\n",
        "      Y.append(y)\n",
        "    else:\n",
        "      y = np.array([((int(j.split('-')[6][1]))%2)])    \n",
        "      Y.append(y)\n",
        "  X = np.array(X)\n",
        "  X = sklearn.preprocessing.scale(X)                  \n",
        "  Y = np.array(Y).reshape(-1,1)\n",
        "  encoder = OneHotEncoder()\n",
        "  Y = encoder.fit_transform(Y).toarray()\n",
        "  XY = np.hstack((X,Y))\n",
        "  np.random.shuffle(XY)                              \n",
        "  X = XY[:,:XY.shape[1]-Y.shape[1]]\n",
        "  Y = XY[:,(XY.shape[1]-Y.shape[1]):]\n",
        "  x_train = X[:math.ceil(train_size*len(X))]\n",
        "  y_train = Y[:math.ceil(train_size*len(X))]\n",
        "  x_test  = X[math.ceil(train_size*len(X)):]\n",
        "  y_test = Y[math.ceil(train_size*len(X)):]\n",
        "\n",
        "  return x_train,y_train,x_test,y_test\n",
        "\n",
        "   #Plotting the losses and accuracy\n",
        "def plotter(history):\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['loss'],label='train loss')\n",
        "  plt.plot(history.history['val loss'],label='test loss')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('losses')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "  plt.plot(history.history['accuracy'],label='train accuracy')\n",
        "  plt.plot(history.history['val accuracy'],label='test accuracy')\n",
        "  plt.xlabel('iterations')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "\n",
        "x_train = np.load('.npy')\n",
        "y_train = np.load('.npy')\n",
        "x_test = np.load('.npy')\n",
        "y_test = np.load('.npy')\n",
        "x_test.shape\n",
        "\n",
        "#building MLP model \n",
        "from keras import models\n",
        "from keras import layers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(input_size, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(layers.Dense(100, activation='relu'))\n",
        "model.add(layers.Dense(50, activation='relu'))\n",
        "model.add(layers.Dense(25, activation='relu'))\n",
        "model.add(layers.Dense(8, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train,epochs=500,batch_size=1440)\n",
        "\n",
        "plotter(history)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
        "print('test_acc: ',test_acc)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "np.argmax(predictions[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}